{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# Used code from Sarcasm with RNN, Random Forest and SVM Python notebook using data from News Headlines Dataset For Sarcasm Detection\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\ndf1 = pd.read_json(\"../input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\", lines = True)\ndf2 = pd.read_json(\"../input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\", lines = True)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-15T12:12:37.095586Z","iopub.execute_input":"2021-07-15T12:12:37.095951Z","iopub.status.idle":"2021-07-15T12:12:37.357999Z","shell.execute_reply.started":"2021-07-15T12:12:37.095916Z","shell.execute_reply":"2021-07-15T12:12:37.357002Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\n/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\n","output_type":"stream"}]},{"cell_type":"code","source":"import regex as re\nsar_acc = pd.read_json('/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json',lines=True)\n#adds a column to dataset called 'source' and it uses the third \"word\" in article_link to identify source\nsar_acc['source'] = sar_acc['article_link'].apply(lambda x: re.findall(r'\\w+', x)[2])\nsar_acc.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T12:12:37.359571Z","iopub.execute_input":"2021-07-15T12:12:37.359871Z","iopub.status.idle":"2021-07-15T12:12:37.878433Z","shell.execute_reply.started":"2021-07-15T12:12:37.359840Z","shell.execute_reply":"2021-07-15T12:12:37.877368Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   is_sarcastic                                           headline  \\\n0             1  thirtysomething scientists unveil doomsday clo...   \n1             0  dem rep. totally nails why congress is falling...   \n2             0  eat your veggies: 9 deliciously different recipes   \n3             1  inclement weather prevents liar from getting t...   \n4             1  mother comes pretty close to using word 'strea...   \n\n                                        article_link          source  \n0  https://www.theonion.com/thirtysomething-scien...        theonion  \n1  https://www.huffingtonpost.com/entry/donna-edw...  huffingtonpost  \n2  https://www.huffingtonpost.com/entry/eat-your-...  huffingtonpost  \n3  https://local.theonion.com/inclement-weather-p...        theonion  \n4  https://www.theonion.com/mother-comes-pretty-c...        theonion  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>is_sarcastic</th>\n      <th>headline</th>\n      <th>article_link</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>thirtysomething scientists unveil doomsday clo...</td>\n      <td>https://www.theonion.com/thirtysomething-scien...</td>\n      <td>theonion</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>dem rep. totally nails why congress is falling...</td>\n      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n      <td>huffingtonpost</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>eat your veggies: 9 deliciously different recipes</td>\n      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n      <td>huffingtonpost</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>inclement weather prevents liar from getting t...</td>\n      <td>https://local.theonion.com/inclement-weather-p...</td>\n      <td>theonion</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>mother comes pretty close to using word 'strea...</td>\n      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n      <td>theonion</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Getting X and Y ready\nfrom sklearn.preprocessing import LabelEncoder\nX = sar_acc.headline\nY = sar_acc.is_sarcastic\nle = LabelEncoder()\n#normalizes Y values and then reshapes Y to have enough rows where each value gets its own row\nY = le.fit_transform(Y)\nY = Y.reshape(-1,1)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T12:12:37.881046Z","iopub.execute_input":"2021-07-15T12:12:37.881575Z","iopub.status.idle":"2021-07-15T12:12:37.890577Z","shell.execute_reply.started":"2021-07-15T12:12:37.881526Z","shell.execute_reply":"2021-07-15T12:12:37.889448Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#splits data with 20% for testing\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T12:12:37.892128Z","iopub.execute_input":"2021-07-15T12:12:37.892530Z","iopub.status.idle":"2021-07-15T12:12:37.907146Z","shell.execute_reply.started":"2021-07-15T12:12:37.892500Z","shell.execute_reply":"2021-07-15T12:12:37.906080Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Tokenize the data and convert the text to sequences.\n# Add padding to ensure that all the sequences have the same shape.\n# There are many ways of taking the max_len and here an arbitrary length of 150 is chosen\n\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nmax_words = 1000\nmax_len = 150\ntok = Tokenizer(num_words=max_words)\ntok.fit_on_texts(X_train)\nsequences = tok.texts_to_sequences(X_train)\nsequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T12:12:37.908674Z","iopub.execute_input":"2021-07-15T12:12:37.909080Z","iopub.status.idle":"2021-07-15T12:12:38.889695Z","shell.execute_reply.started":"2021-07-15T12:12:37.909011Z","shell.execute_reply":"2021-07-15T12:12:38.888715Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\nfrom keras.optimizers import RMSprop\nfrom keras.models import Model\n\ndef RNN():\n    inputs = Input(name='inputs',shape=[max_len])\n#     adding words to the layer of NN\n    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n#     adding LTSM to layer -- long short term memory type of RNN but covers longer distance\n    layer = LSTM(64)(layer)\n#     adding dense layer -- fully connected will just continue\n    layer = Dense(256,name='FC1')(layer)\n#     adding the relu activation function\n    layer = Activation('relu')(layer)\n#     adding dropout pf 20% to prevent overfitting\n    layer = Dropout(0.2)(layer)\n#     adding the dense layer\n    layer = Dense(1,name='out_layer')(layer)\n#     adding sigmoid activation function\n    layer = Activation('sigmoid')(layer)\n#     initializing the model of RNN based on inputs and layers\n    model = Model(inputs=inputs,outputs=layer)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-15T12:12:38.891487Z","iopub.execute_input":"2021-07-15T12:12:38.891928Z","iopub.status.idle":"2021-07-15T12:12:38.900750Z","shell.execute_reply.started":"2021-07-15T12:12:38.891882Z","shell.execute_reply":"2021-07-15T12:12:38.899581Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# calling the model of RNN\nmodel = RNN()\n# generating the summary of the model formed\nmodel.summary()\n# compiling the model and assigning loss function and optimizer\nmodel.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-07-15T12:12:38.902384Z","iopub.execute_input":"2021-07-15T12:12:38.902814Z","iopub.status.idle":"2021-07-15T12:12:39.557116Z","shell.execute_reply.started":"2021-07-15T12:12:38.902768Z","shell.execute_reply":"2021-07-15T12:12:39.556161Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninputs (InputLayer)          [(None, 150)]             0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 150, 50)           50000     \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 64)                29440     \n_________________________________________________________________\nFC1 (Dense)                  (None, 256)               16640     \n_________________________________________________________________\nactivation_2 (Activation)    (None, 256)               0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 256)               0         \n_________________________________________________________________\nout_layer (Dense)            (None, 1)                 257       \n_________________________________________________________________\nactivation_3 (Activation)    (None, 1)                 0         \n=================================================================\nTotal params: 96,337\nTrainable params: 96,337\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping\n# fitting the model\nmodel.fit(sequences_matrix,Y_train,batch_size=100,epochs=5,\n          validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])","metadata":{"execution":{"iopub.status.busy":"2021-07-15T12:12:39.558346Z","iopub.execute_input":"2021-07-15T12:12:39.558630Z","iopub.status.idle":"2021-07-15T12:14:10.043770Z","shell.execute_reply.started":"2021-07-15T12:12:39.558601Z","shell.execute_reply":"2021-07-15T12:14:10.042619Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/5\n207/207 [==============================] - 31s 142ms/step - loss: 0.5588 - accuracy: 0.6934 - val_loss: 0.4332 - val_accuracy: 0.7886\nEpoch 2/5\n207/207 [==============================] - 30s 143ms/step - loss: 0.3815 - accuracy: 0.8244 - val_loss: 0.3912 - val_accuracy: 0.8140\nEpoch 3/5\n207/207 [==============================] - 30s 143ms/step - loss: 0.3643 - accuracy: 0.8340 - val_loss: 0.4072 - val_accuracy: 0.8157\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7efdf8425710>"},"metadata":{}}]},{"cell_type":"code","source":"# creating test sequence from text\ntest_sequences = tok.texts_to_sequences(X_test)\n# creating test sequence matrix using above created test sequence\ntest_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T12:14:10.046046Z","iopub.execute_input":"2021-07-15T12:14:10.046391Z","iopub.status.idle":"2021-07-15T12:14:10.185089Z","shell.execute_reply.started":"2021-07-15T12:14:10.046355Z","shell.execute_reply":"2021-07-15T12:14:10.184129Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# initializing accuracy matrix to store accuracies of all the models and compare them\naccuracy = {}","metadata":{"execution":{"iopub.status.busy":"2021-07-15T12:14:10.186947Z","iopub.execute_input":"2021-07-15T12:14:10.187497Z","iopub.status.idle":"2021-07-15T12:14:10.192273Z","shell.execute_reply.started":"2021-07-15T12:14:10.187448Z","shell.execute_reply":"2021-07-15T12:14:10.191155Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# evaluation of RNN model\naccr = model.evaluate(test_sequences_matrix,Y_test)\n# printing the loss and accuracy of our model\nprint('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n# storing the model name and accuracy in accuracy dictionary\naccuracy.update({\"RNN\":accr[1]})","metadata":{"execution":{"iopub.status.busy":"2021-07-15T12:14:10.193635Z","iopub.execute_input":"2021-07-15T12:14:10.194043Z","iopub.status.idle":"2021-07-15T12:14:14.076209Z","shell.execute_reply.started":"2021-07-15T12:14:10.194014Z","shell.execute_reply":"2021-07-15T12:14:14.075092Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"179/179 [==============================] - 4s 21ms/step - loss: 0.4204 - accuracy: 0.8096\nTest set\n  Loss: 0.420\n  Accuracy: 0.810\n","output_type":"stream"}]}]}